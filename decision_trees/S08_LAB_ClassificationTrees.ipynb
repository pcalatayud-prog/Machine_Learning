{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Árboles de clasificación\n",
    "#### Rodrigo Manzanas\n",
    "##### 25-Noviembre-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la práctica de hoy vamos a profundizar un poco más sobre algunos de los conceptos que se han visto en la sesión de teoría. En particular, veremos cómo se trabaja para encontrar la configuración óptima de un árbol de clasificación, para lo cual necesitamos tener presentes las nociones ya vistas de overfitting (sobreajuste) y cross-validación. Utilizaremos los paquetes *tree*, *rpart* y *caret*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    }
   ],
   "source": [
    "# loading libraries\n",
    "library(tree)\n",
    "library(rpart)\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lugar, carga en tu sesión de `R` el dataset con el que vamos a trabajar, *Carseats* (incluido en el paquete *ISLR*). Antes de arrancar, dedica unos minutos para familiarizarte con él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ISLR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertiremos la variable continua *Sales* (cantidad de carritos vendidos, en miles de unidades) a categórica (de tipo factor), que podrá tomar los valores *No* (valores menores o iguales a 8) y *Yes* (valores mayores que 8). Este nuevo factor será nuestra variable objetivo a clasificar durante la práctica (el resto de variables serán nuestros predictores). Por conveniencia, la vamos a renombar como *high*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert continuous variable \"Sales\" to categorical\n",
    "dataset = Carseats  # renombro el dataset por comodidad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a definir una nueva función (nómbrala *acc.class*) que calcule la métrica de validación que utilizaremos a lo largo de toda la práctica; el ratio de aciertos o *accuracy*. Para ello apóyate en la función `table` (paquete `base` de `R`), que genera una tabla de contingencia entre dos variables que puedan ser interpretadas como factores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     var2\n",
       "var1  no yes\n",
       "  no   2   0\n",
       "  yes  1   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## use of function table\n",
    "var1 = c(\"no\", \"no\", \"yes\",\"yes\")\n",
    "var2 = c(\"no\", \"no\", \"no\",\"yes\")\n",
    "table(var1, var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation function\n",
    "acc.class = function(x, y) {\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora dividimos el dataset total en dos mitades independientes de train y test, escogidas aleatoriamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## independent train and test \n",
    "n = nrow(dataset)\n",
    "set.seed(25)  # fijo una semilla para asegurar la reproducibilidad de los resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer objetivo de la práctica es obtener, manualmente, la configuración óptima del árbol (aquella que minimiza el error de test, para no caer en sobreajuste). Para ello debemos ver cómo evoluciona el error de clasificación en el train y en el test, en función de la complejidad del árbol. \n",
    "\n",
    "**Ejercicio:** \n",
    "\n",
    "Entrena un árbol con la función *tree* (configuración por defecto) utilizando el dataset de train. ¿Cuántas hojas tiene? A continuación, ve podando ese árbol (escoje valores para el número de hojas entre 3 y 15) y calcula su accuracy para clasificar, tanto sobre el dataset de train como sobre el de test. Dibuja ambos errores en función del número de hojas e interpreta los resultados. ¿Cuál sería la configuración óptima del árbol?  \n",
    "**Nota**: Utiliza la función *prune.tree* (argumento *best*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pruning the tree to find the optimal configuration \n",
    "# complete tree\n",
    "\n",
    "acc.train = c()\n",
    "acc.test = c()\n",
    "nleaf = 3:15\n",
    "for (n in nleaf) {\n",
    "  # pruning the complete tree (based on parameter \"best\")\n",
    "  \n",
    "  # performance on training data\n",
    "  \n",
    "  # performance on test data\n",
    "  \n",
    "}\n",
    "# plot results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza la función *cv.tree* para hacer una cross-validación 10-fold sobre el dataset de train. ¿A qué conclusión llegas?  \n",
    "**Idea:** Busca en el objeto de salida que te devuelve *cv.tree* y dibuja el factor de desviación (medida que da idea del error de clasificación) en función del número de hojas del árbol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete tree\n",
    "\n",
    "# 10-fold cross-validated tree\n",
    "\n",
    "# plot results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos encontrado la configuración óptima (número de hojas) de nuestro árbol, evalúa el accuracy del árbol obtenido por defecto y el del óptimo, tanto en train como en test. ¿Qué conclusión obtienes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## performance in train\n",
    "\n",
    "# complete tree\n",
    "\n",
    "# optimum tree\n",
    "\n",
    "## performance in test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibuja el árbol por defecto y el óptimo para ver la diferencia en complejidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos obtenido la configuración ótpima del árbol en función del número de hojas del mismo. La idea ahora es fijarnos en otro parámetro, la profundidad del árbol (ambos conceptos están relacionados). Para ello, aprende un conjunto de árboles de diferente profundidad (de 1 a 10 niveles) utilizando el dataset de train y evalúa su accuracy para clasificar en el test. Dibuja dicho accuracy en función de la profundidad del árbol. ¿Cuál sería la configuración óptima en este caso? Compara el accuracy obtenido para esta configuración con el que obteníamos en el ejercicio anterior.  \n",
    "**Nota:** Usa la función *rpart* (parámetro *maxdepth*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = 1:10  # maximum depth\n",
    "acc.test = c()\n",
    "\n",
    "for (i in md) {\n",
    "  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El paquete *caret* pemite evaluar de forma sencilla la idoneidad de varios parámetros de configuración del árbol considerando distintos tipos de cross-validación.  \n",
    "\n",
    "**Ejercicio:** \n",
    "\n",
    "Utilizando la función *train* de *caret* (method *rpart2*), calcula el accuracy que se obtiene para 3 árboles de distinta profundidad (valores escogidos internamente por *caret*) bajo un esquema de cross-validación con 5 folds. Dibuja los resultados.  \n",
    "**Preguntas:** ¿Cuál dirías que es la configuración óptima del árbol en este caso? ¿Los resultados son diferentes a lo que esperabas obtener? ¿A qué puede deberse?  \n",
    "**Nota:** La siguiente página ofrece una documentación muy buena de *caret*: https://topepo.github.io/caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-validation with 5 folds\n",
    "#trctrl = *** \n",
    "\n",
    "## caret automatically tries different values of the method's parameter: internal selection\n",
    "#t = train(***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lugar de dejar que *caret* seleccione internamente los valores del parámetro a configurar (en este caso *maxdepth*), podemos especificárselos nosotr@s. Para ello hay que definir el *grid* que va a considerar *caret* (argumento *tuneGrid*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preguntas:** Los resultados han cambiado, ¿por qué? ¿Qué pasa si ejecutas varias veces el bloque de código anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** \n",
    "\n",
    "Para comprobar el efecto que tiene en nuestros resultados la elección de los subconjuntos de train y test, repite el ejercicio anterior 20 veces, salvando en cada iteración la profundidad del árbol óptimo (prueba valores entre 1 y 10).  \n",
    "**Pregunta:** A la vista de los resultados, ¿dirías que es importante tener en cuneta el efecto de la partición train/validation durante el proceso de optimización del árbol?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## effect of train/test partition on optimum depth\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio:** Una vez hemos definido una profundidad óptima para nuestro árbol, comprueba ahora cuál sería el efecto de la partición train/validation sobre el accuracy.  \n",
    "**Idea:** Reutiliza el código anterior. Entre muchas otras cosas, la función *train* devuelve lo que estás buscando. Da una estimación (valor promedio +/- margen de incertidumbre) del accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## effect on accuracy of train/test partition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio anterior puede hacerse en `caret` de forma mucho más sencilla simplemente con cambiar el modo en el que definimos la cross-validación.\n",
    "\n",
    "**Ejercicio:** Revisa la documentación de la función *trainControl* y replica el ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## previous block with caret\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lógicamente, el número de folds considerados también puede tener un efecto en la búsqueda de la configuración óptima del árbol. \n",
    "\n",
    "**Ejercicio:** Comprueba cómo varía la profundidad óptima del árbol (posibles valores entre 1 y 10) al cambiar el número de folds (desde 3 hasta 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## effect of number of folds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
