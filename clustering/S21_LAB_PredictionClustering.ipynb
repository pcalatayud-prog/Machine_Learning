{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minería de Datos (Master en Data Science, UIMP-UC)\n",
    "\n",
    "## S21. Predicción condicionada a clústering\n",
    "\n",
    "### Rodrigo Manzanas   \n",
    "#### 24 Enero 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "En esta práctica vamos a utilizar el método *k-means* para realizar una predicción condicionada a tipos de tiempo (weather types en inglés, *WTs*), es decir a patrones atmosféricos característicos definidos como los centroides de un número determinado de clústers. Trabajaremos para ello con el dataset `meteo`, que ya ha sido utilizado en anteriores sesiones. Como sabes, la variable objetivo en este dataset es la precipitation diaria en Lisboa durante el período 1979-2008, y para predecirla se dispone de 320 predictores que describen la circulación atmosférica de larga escala. Dichos predictores corresponden a un conjunto de 8 variables meteorológicas en diferentes niveles verticales\n",
    "\n",
    "* altura geopotencial en 500 hPa (Z500)\n",
    "* temperatura en 850 hPa, 700 hPa, 500 hPa y en superficie (T850, T700, T500, 2T)\n",
    "* humedad específica en 850 hPa y 500 hPa (Q850, Q500)\n",
    "* presión a nivel del mar (SLP)\n",
    "\n",
    "definidas sobre un dominio geográfico que incluye 40 puntos (8 en la longitud y 5 en la latitud) sobre la península Ibérica.\n",
    "\n",
    "Comenzamos cargando el dataset y separando el predictando (vector *y*) de los predictores (matriz *x*). Por conveniencia, renombraremos las columnas de *x* utilizando las etiquetas *Z500, T850, T700, T500, 2T, Q850, Q500* y *SLP*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list = ls())\n",
    "\n",
    "## loading data\n",
    "data = read.csv(\".../meteo.csv\")\n",
    "y = data[, 2]  # predictand\n",
    "x = data[, -c(1,2)]  # predictors: Z500,T850,T700,T500,2T,Q850,Q500,SLP\n",
    "rm(data)\n",
    "\n",
    "lon = seq(-10, 4, 2) # 2º resolution\n",
    "lat = seq(36, 44, 2) # 2º resolution\n",
    "\n",
    "## naming columns\n",
    "colnames(x) = c(rep(\"Z500\", length(lon)*length(lat)),\n",
    "  rep(\"T850\", length(lon)*length(lat)),\n",
    "  rep(\"T700\", length(lon)*length(lat)),\n",
    "  rep(\"T500\", length(lon)*length(lat)),\n",
    "  rep(\"2T\", length(lon)*length(lat)),\n",
    "  rep(\"Q850\", length(lon)*length(lat)),\n",
    "  rep(\"Q500\", length(lon)*length(lat)),\n",
    "  rep(\"SLP\", length(lon)*length(lat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para familiarizarnos un poco más con el dataset, dibuja la climatología de cada una de las 8 variables predictoras. Puedes utilizar para ello la función *image.plot* del paquete *fields*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(fields)\n",
    "library(maps)\n",
    "par(mfrow = c(2, 4))  # configuring figure layout\n",
    "for (var in unique(colnames(x))) {\n",
    "  image.plot(x = lon, y = lat, \n",
    "             z = t(matrix(colMeans(x[ , colnames(x) == var]), \n",
    "                          nrow = length(lat), \n",
    "                          ncol = length(lon))),\n",
    "             xlab = \"lon (º)\", ylab = \"lat (º)\", main = var,\n",
    "            asp = 1)\n",
    "  map(add = T)  # overlapping map\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación partiremos el dataset en train y test (75% y 25% de los datos, respectivamente), de forma aleatoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "\n",
    "# train/test random splitting (75% and 25%, respectively)\n",
    "n = length(y)\n",
    "indtrain = sort(sample(n, round(0.75*n)))\n",
    "indtest = setdiff(1:n, indtrain)\n",
    "\n",
    "# 75% train\n",
    "x.train = x[indtrain, ]\n",
    "y.train = y[indtrain]\n",
    "\n",
    "# 25% test\n",
    "x.test = x[indtest, ]\n",
    "y.test = y[indtest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN (análogos, en meteorología)\n",
    "\n",
    "### k-NN no condicionado\n",
    "Comenzaremos nuestra práctica obteniendo la predicción para el período de test utilizando la técnica *k-NN*, considerando un único vecino (*1-NN*). Para ello, tendrás que utilizar la función *knn.reg* del paquete *FNN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(FNN)\n",
    "## 1-NN prediction\n",
    "\n",
    "## plotting observed and predicted series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para validar esta predicción vamos a utilizar algunas de las métricas que hemos venido utilizando durante el curso, en particular el *accuracy* (tasa de aciertos) para la parte binaria lluvia/no lluvia y el RMSE, la correlación de Spearman y el ratio de varianzas para la parte continua. Consideremos *1mm* como umbral para discernir entre días secos y húmedos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation\n",
    "# accuracy (binary occurrence event)\n",
    "acc.class = function(x, y) {\n",
    "  stopifnot(length(x) == length(y))\n",
    "  return(sum(diag(table(x, y))) / length(x))\n",
    "}\n",
    "# RMSE (continuous amount event)\n",
    "rmse = function(x, y) {\n",
    "sqrt(mean((x - y)^2))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede apreciar, los resultados son bastante buenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN condicionado a WTs\n",
    "Veamos ahora qué sucedería al aplicar la misma técnica *1-NN* condicionada a un *k-means* con *k=10*. Ten en cuenta que la inicialización del *k-means* es aleatoria, por lo que conviene repetir el proceso de clustering un número de veces \"razonablemente\" alto, por ejemplo 20. Valida tu nueva predicción en función de las mismas métricas utilizadas en el ejemplo anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "## k-means with k=10\n",
    "\n",
    "## observed precipitation corresponding to the centroids\n",
    "\n",
    "## 1-NN prediction\n",
    "\n",
    "## validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son peores. ¿Puedes intuir por qué? Dibuja la predicción que acabas de obtener junto a la serie observada. ¿Qué observas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repite el mismo proceso para *k=50*. A continuación, dibuja y valida la predicción obtenida. ¿Se aprecian diferencias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "## k-means with k=50\n",
    "\n",
    "## observed precipitation corresponding to the centroids\n",
    "\n",
    "## 1-NN prediction\n",
    "\n",
    "## validation\n",
    "\n",
    "## plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabes, el método *k-means* puede resultar poco conveniente cuando no se tiene una idea a priori sobre el número de clústers (*k*) que se necesitan para caracterizar adecuadamente el dataset. Por tanto, vamos a realizar un estudio de sensibilidad a este factor repitiendo la predicción *1-NN*, y su correspondiente validación, para distintos *k* desde 10 hasta 300, en intervalos de 50. Mide el tiempo que se emplea en dicho proceso (puedes utilizar la función *Sys.time()*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-means with varying k\n",
    "t1 = Sys.time()\n",
    "val = c()  # initializing validation matrix \n",
    "nclus = seq(10, 300, 50)\n",
    "for (k in nclus) {\n",
    "    print(paste(\"... k =\", k, \"...\"))\n",
    "    \n",
    "    set.seed(555)\n",
    "    ***\n",
    "    \n",
    "    val = cbind(val, ***)\n",
    "}\n",
    "t2 = Sys.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotea los resultados de la validación para cada métrica, en función del número de clústers considerado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En principio, el mayor efecto de la elección del número de clústers se da sobre la correlación y el ratio de varianzas, sin embargo, los resultados son en general muy inestables, por lo que la elección del *k* \"óptimo\" no es para nada trivial.\n",
    "\n",
    "**Pregunta**: ¿Qué crees que pasaría para *k* altos, por ejemplo 4000?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabes, las variables atmosféricas que estamos considerando como predictores están altamente correlacionadas (tanto en el espacio como en el tiempo), por lo que podría resultar útil trabajar en el espacio de las componentes principales (PCs), lo que nos permitiría eliminar redundancia y reducir la dimensionalidad de nuestro problema.\n",
    "\n",
    "**Pregunta:** ¿Crees que usar PCs en lugar de los campos crudos puede alterar los resultados que estamos obteniendo? Repite el experimento anterior, pero esta vez utilizando las PCs que expliquien el 95% de la varianza en lugar de los campos crudos. Mide de nuevo el tiempo invertido en todo el proceso. Compara los resultados obtenidos con los campos crudos y con las PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "pca = prcomp(x.train, center = T, scale. = T)  # recall it's important to standardize all predictor fields prior to PCA\n",
    "exp.var = cumsum(pca$sdev^2)/sum(pca$sdev^2) # cumulative proportion of explained variance\n",
    "plot(exp.var, type = \"b\", xlab = \"no. of PCs\", ylab = \"cumulative exp. var.\")\n",
    "grid()\n",
    "\n",
    "nPC = sum(exp.var < 0.95)  # no. of PCs needed to explain a 95% of variance in the predictors\n",
    "print(nPC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## projecting PCs\n",
    "pc = predict(pca, x)\n",
    "\n",
    "## k-means with varying k\n",
    "t1 = Sys.time()\n",
    "\n",
    "t2 = Sys.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son en general peores para las PCs que para los campos crudos, ¿puedes imaginar por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos experimentando con clústers \"arbitrarios\". Sin embargo, vamos a ver que para ciertos valores de *k*, el clústering al que se llega ofrece cierta interpretabilidad. Por ejemplo, si escogemos un *k=4*, los clústers resultantes podrían identificarse con las estaciones del año. Para comprobarlo, dibuja la climatología observada para la temperatura en superficie (2T) en los 4 clústers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-means with k=4\n",
    "nclus = 4  # ~ seasons of the year\n",
    "set.seed(555)\n",
    "km = kmeans(x.train, nclus, iter.max = 1000, nstart = 20)\n",
    "\n",
    "## climatology for 2T in each cluster\n",
    "par(mfrow = c(2, 2))\n",
    "for (iclus in 1:nclus) {\n",
    "  z = colMeans(x.train[km$cluster == iclus, colnames(x) == \"2T\"])  \n",
    "  image.plot(x = lon, y = lat, \n",
    "             z = t(matrix(z, \n",
    "                          nrow = length(lat), \n",
    "                          ncol = length(lon))),\n",
    "             zlim = c(275, 300),\n",
    "             xlab = \"lon (º)\", ylab = \"lat (º)\", \n",
    "             main = paste(\"2T, cluster\",iclus))\n",
    "  map(add = T)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula ahora la climatología observada para la precipitación en Lisboa en cada uno de los 4 clústers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.clus = c()\n",
    "for (iclus in 1:nclus) {\n",
    "  ind.clus = which(km$cluster == iclus)\n",
    "  mean.clus[iclus] = mean(y.train[ind.clus])\n",
    "}\n",
    "plot(1:nclus, mean.clus, type = \"b\", xlab = \"clúster\", ylab = \"mm/day\")\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, se pueden identificar las 4 estaciones del año. Comprobemos qué resultados se obtendrían condicionando el método *1-NN* a un *k-means* con 4 WTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "## k-means with k=4\n",
    "\n",
    "## validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿A qué crees que se debe el desplome en el ratio de varianzas? ¿Se te ocurre alguna estrategia para aliviar este problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hecho el *4-means* habrá que identificar, para cada día del test, cuál de los centroides que has obtenido es el más parecido al patrón atmosférico del día en cuestión.\n",
    "\n",
    "**Pista:** Puedes usar la función *dist*, que te permitirá calcular la distancia euclídea entre patrones atmosféricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "## k-means with k=4\n",
    "km = kmeans(x.train, 4, iter.max = 1000, nstart = 20)\n",
    "## distances, for each day in test, to each of the 4 centroids\n",
    "dist.euc = dist(rbind(x.test, km$centers), method = \"euclidean\")\n",
    "dist.euc = as.matrix(dist.euc)\n",
    "## extracting submatrix of interest\n",
    "dist.euc = dist.euc[1:nrow(x.test), -c(1:nrow(x.test))]  \n",
    "## vector indicating, for each day in test, the nearest centroid\n",
    "clus = apply(dist.euc, 1, \"which.min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se trata de utilizar tan sólo los días (del train) que caen dentro del clúster representado por dicho centroide para ajustar un modelo estocástico, que constará de dos pasos. Primero, se calcula la probabilidad de lluvia en ese clúster (llamémosla *p.rain*). Seguidamente, se trata de ajustar los parámetros de una función Gamma (*shape* y *rate*) a partir de los días de lluvia del clúster (necesitarás para ello la función *fitdist* del paquete *fitdistrplus*). Finalmente, a partir de los parámetros *p.rain*, *shape* y *scale* se simulará un valor predicho para ese día concreto del test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(fitdistrplus)\n",
    "## obtaining p.rain, shape and rate for each cluster\n",
    "p.rain.clus = c()  \n",
    "shape.clus = c()\n",
    "rate.clus = c()\n",
    "for (iclus in sort(unique(clus))) {\n",
    "  ind.train = which(km$cluster == iclus)  # days (in train) within target cluster\n",
    " \n",
    "  ## rain probability and Gamma parameters (fitted within target cluster)\n",
    "}\n",
    "\n",
    "## generating stochastic prediction for each day in test\n",
    "pred = c()\n",
    "#for (iday in 1:nrow(x.test)) {\n",
    "  # p.rain, shape and scale parameters used to generate a predicted value for that day in test  \n",
    "\n",
    "    # simulating a predicted value (stochastically)  \n",
    "  #if (runif(1) < p.rain) {\n",
    "    \n",
    "  #} else {\n",
    "    \n",
    "  #}\n",
    "#}\n",
    "\n",
    "## validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, el ratio de varianzas ha mejorado notablemente. Sin embargo, como consecuencia del proceso de estocastización, la correlación ha bajado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Crees que el número de vecinos cercanos considerados en el método *k-NN* puede influir en los resultados que estamos obteniendo? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos lineales generalizados (GLMs):\n",
    "\n",
    "Pasemos ahora a utilizar GLMs para abordar nuestro problema, la predicción de lluvia diaria en Lisboa. Dado el carácter mixto (discreto/continuo) de esta variable, habrá que realizar el proceso en dos pasos: en primer lugar se estimará la ocurrencia y a continuación la cantidad. Para ello, consideraremos la familia `binomial` con función de enlace `logit` (regresión logística) para el evento binario \"ocurrencia de lluvia\" y la familia `Gamma` con función de enlace `log` para el evento continuo \"cantidad de lluvia\".\n",
    "\n",
    "### GLM no condicionado\n",
    "Comencemos construyendo el GLM de ocurrencia, basándonos para ello en los campos crudos (las 320 variables predictoras de que disponemos) en el período de train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary occurrence\n",
    "occ = y\n",
    "occ[which(y < 1)] = 0\n",
    "occ[which(y >= 1)] = 1\n",
    "\n",
    "## data frame for occurrence\n",
    "df.occ = data.frame(y.occ = occ, predictors = x)\n",
    "\n",
    "## GLM for occurrence (logistic regression in train period)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos ajustado el modelo, lo utilizamos para predecir en el test. Tenemos que convertir la predicción probabilística obtenida en binaria (considera para ello un umbral 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## occurrence prediction for test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, construiremos el GLM para la cantidad. Para su ajuste, tenemos que seleccionar previamente, dentro del train, los días de lluvia (la familia Gamma sólo acepta valores positivos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data frame for amount\n",
    "df.amo = data.frame(y.amo = y, predictors = x)\n",
    "\n",
    "## selecting rainy days\n",
    "indrain = which(y > 1)\n",
    "\n",
    "## GLM for amount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y utilizamos el modelo para predecir en el test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## amount prediction for test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Llegados a este punto, multiplicaremos las predicciones de ocurrencia y cantidad obtenidas para el test y validaremos la serie resultante, utilizando las mismas métricas de validación que empleamos para el caso de la técnica *k-NN*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation (for test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compara estos resultados con los que se obtuvieron para el método *1-NN* (no condicionado)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los métodos de regresión, y en particular en los GLM, el efecto de la colinealidad en los datos de entrada (predictores) puede dar lugar a ajustes muy deficientes. Por tanto, sería conveniente analizar qué resultados de validación se obtendrían si se utilizasen como predictores las PCs que expliquen el 95% de la varianza en lugar de los campos crudos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### GLM for occurrence #####\n",
    "## data frame for occurrence containing the PCs as predictors\n",
    "df.occ.pca = data.frame(y.occ = occ, predictors = pc[, 1:nPC])\n",
    "\n",
    "## GLM for occurrence (considering PCs)\n",
    "\n",
    "## predicting occurrence (for test)\n",
    "\n",
    "##### GLM for amount #####\n",
    "## data frame for amount containing the PCs as predictors\n",
    "df.amo.pca = data.frame(y.amo = y, predictors = pc[, 1:nPC])\n",
    "\n",
    "## GLM for amount (considering PCs)\n",
    "\n",
    "## predicting amount (for test)\n",
    "\n",
    "##### validation (for test) #####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son peores. ¿Qué interpretación le das?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLM condicionado a WTs\n",
    "A continuación, similarmente a como hicimos en el caso de la predicción estocástica, vamos a condicionar la predicción con GLMs a un clústering sobre tipos de tiempo. Empecemos por un *k-means* con 4 tipos de tiempo. Para ello, una vez hecho el *k-means* (sobre los predictores crudos), tendrás que identificar, para cada día del test, cuál de los centroides que has obtenido es el más parecido al patrón atmosférico del día en cuestión. A continuación, tendrás que ajustar los dos GLM (ocurrencia y cantidad) utilizando tan sólo los días (del train) que caen dentro del clúster representado por dicho centroide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "## k-means with k=4\n",
    "km = kmeans(x.train, 4, iter.max = 1000, nstart = 20)\n",
    "## distances, for each day in test, to each of the 4 centroids\n",
    "dist.euc = dist(rbind(x.test, km$centers), method = \"euclidean\")\n",
    "dist.euc = as.matrix(dist.euc)\n",
    "## extracting submatrix of interest\n",
    "dist.euc = dist.euc[1:nrow(x.test), -c(1:nrow(x.test))]  \n",
    "## vector indicating, for each day in test, the nearest centroid\n",
    "clus = apply(dist.euc, 1, \"which.min\")\n",
    "\n",
    "pred = c()  # initializing prediction vector\n",
    "#for (iclus in sort(unique(clus))) {\n",
    "  #print(paste(\"... cluster\", iclus, \"...\"))\n",
    "  \n",
    "  # days (in train) within target cluster\n",
    "  \n",
    "  # days (in test) whose atmospheric pattern corresponds to the target cluster\n",
    "  \n",
    "  ## GLM for occurrence (fitted within target cluster)\n",
    "  \n",
    "  ## GLM for amount (fitted within target cluster)\n",
    "  \n",
    "  ## complete prediction, properly placed \n",
    "  \n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Han salido muchos \"warnings\", ¿intuyes a qué pueden deberse? Dibuja la serie predicha que has obtenido, ¿qué observas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(pred, type = \"l\", xlab = \"days\", ylab = \"mm\")\n",
    "grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fíjate que, debido al condicionamiento al clústering, disminuye el número de observaciones que se utilizan en los ajustes, por lo que el efecto de la colinealidad en los predictores se torna más relevante. Como consecuencia, es frecuente encontrarse en este tipo de situaciones con GLMs que no han podido ajustarse bien y pueden dar lugar a NAs o a outliers (valores de precipitación anómalamente altos), que hay que eliminar. Para ello se pueden considerar distintos criterios (todos ellos, hasta cierto punto, arbitrarios), tales como deshacerse de los valores que superen un determinado número de veces el valor máximo observado. Nosotros, en este ejemplo, eliminaremos todos los valores predichos que se sitúen tres veces por encima del percentil 99 observado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[pred > quantile(y.test, 0.99)*3] = NA   # removing outliers\n",
    "plot(pred, type = \"l\", xlab = \"days\", ylab = \"mm\")\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compara estos resultados con los que obtuviste para el GLM no condicionado. ¿Qué conclusiones obtienes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para finalizar la práctica, repite el experimento anterior (GLM condicionado a clústering) para un número alto de tipos de tiempo, por ejemplo 100. ¿Qué sucede? **Pregunta:** ¿Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(555)\n",
    "## k-means with k=100\n",
    "\n",
    "## distances, for each day in test, to each of the 100 centroids\n",
    "\n",
    "## extracting submatrix of interest\n",
    "\n",
    "## vector indicating, for each day in test, the nearest centroid\n",
    "\n",
    "pred = c()  # initializing prediction vector\n",
    "#for (iclus in sort(unique(clus))) {\n",
    "  #print(paste(\"... cluster\", iclus, \"...\"))\n",
    "  \n",
    "  # days (in train) within target cluster\n",
    "  # days (in test) whose atmospheric pattern corresponds to the target cluster\n",
    "  \n",
    "  ## GLM for occurrence (fitted within target cluster)\n",
    "  \n",
    "  ## GLM for amount (fitted within target cluster)\n",
    "  \n",
    "  ## complete prediction, properly placed \n",
    "  \n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pregunta:** ¿Qué se te ocurre para solucionar este problema? \n",
    "Intenta solventar esta limitación y valida la predicción que obtienes con *k=100*. ¿Qué resultados obtienes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## avoiding errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing outliers and plotting\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
