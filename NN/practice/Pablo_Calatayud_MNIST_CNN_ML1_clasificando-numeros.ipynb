{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Introducción a las convnets: Clasificando números\n",
    "\n",
    "\n",
    "\n",
    "Vamos a echarle un vistazo a un ejemplo sencillo de una convnet. La utilizaremos para clasificar el dataset MNIST, que es un dataset abierto que contiene números escritos a mano. \n",
    "\n",
    "![Números escritos a mano del dataset MNIST](http://corochann.com/wp-content/uploads/2017/02/mnist_plot.png)\n",
    "\n",
    "Vamos a crear una primera convnet basica. Es una pila de capas `Conv2D` y `MaxPooling2D`. \n",
    "Lo importante es notar que una convnet toma como input tensores de tamaño `(altura_imagen, anchura_imagen, canales_imagen)`. \n",
    "Para ello primero hay que averiguar el tamaño de las imágenes de nuestro dataset. \n",
    "\n",
    "La red debe tener las siguientes capas:\n",
    "\n",
    "- Una capa convolucional (Conv2D) con 32 filtros de 3x3 y activación relu. En esta primera capa deberás indicar el tamaño del input (input_shape).\n",
    "- Una segunda capa de Max Pooling (MaxPooling2D) de 2x2\n",
    "- Una tercera capa convolucional con 64 filtros de 3x3 y activación relu\n",
    "- Una cuarta capa de Max Pooling (MaxPooling2D) de 2x2\n",
    "- Una quinta capa convolucional de 64 filtros de 3x3 y activación relu\n",
    "\n",
    "Sabrás que lo has hecho bien cuando el output de model.summary() sea:\n",
    "\n",
    "![imagen_output.png](https://github.com/laramaktub/MachineLearningI/blob/master/imagen_output.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import backend as K \n",
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Puedes ver arriba que la salida de cada capa `Conv2D` y `MaxPooling2D` es un tensor 3D de dimensiones `(altura, anchura, canales)`. La anchura y la altura tienden a diminuir según vamos yendo mas profundo en la red. El número de canales está controlado por el primer argumento que se le pasa a \n",
    "las capas `Conv2D`  (e.j. 32 o 64).\n",
    "\n",
    "El siguiente paso sería darle nuestro ultimo tensor (de dimensiones `(3, 3, 64)`) como entrada a una red densamente conectada. \n",
    "Estos clasificadores procesan vectores, que son 1D,  mientras que nuestra salida es un tensor 3D. \n",
    "Así que primero tendremos que aplanar nuestra salida 3D y convertirla en 1D y después añadir unas cuantas capas densas:\n",
    "\n",
    "- Primero aplana la salida (flatten())\n",
    "- Añade una primera capa de 64 neuronas y activación relu\n",
    "- Añade una última capa de 10 neuronas (tantas como números puedes clasificar) y activación softwmax\n",
    "\n",
    "Sabrás que lo has hecho bien cuando el summary tenga esta pinta:\n",
    "\n",
    "![imagen_output_flat.png](https://github.com/laramaktub/MachineLearningI/blob/master/imagen_output_flat.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queremos clasificar 10 categorías, lo que significa que nuestra capa final debe tener 10 nodos y una función de activación softmax. Vamos a ver que pinta tiene nuestra red:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes ver, nuestra salida de dimension `(3, 3, 64)` han sido aplanadas hasta convertirse en vectores de dimensión `(576,)`, antes de entrar en las dos capas densas.\n",
    "\n",
    "Vamos ahora a entrenar nuestra red con las imágenes del dataset MNIST.\n",
    "\n",
    "Leemos a continuación el dataset y lo metemos dentro de vectores: train_images, train_labels, test_images, test_labels\n",
    "\n",
    "Antes de continuar, imprime:\n",
    "\n",
    "- ¿Cual es el tamaño del dataset de training?\n",
    "- ¿Qué pinta tiene el dataset de training?\n",
    "- ¿Qué pinta tienen las etiquetas de training?\n",
    "- Imprime la cuarta imagen del dataset de training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation\n",
    "from keras import backend as k\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del data set Training Predictores:\n",
      "(60000, 28, 28)\n",
      "Tamaño del data set Training Predictando:\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "#1. ¿Cual es el tamaño del dataset de training?\n",
    "print(\"Tamaño del data set Training Predictores:\")\n",
    "print(x_train.shape)\n",
    "print(\"Tamaño del data set Training Predictando:\")\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. ¿Qué pinta tiene el dataset de training?\n",
    "x_train\n",
    "#Cada valor es una matriz de 28x28 donde si hay un 0 significa un pixel negro y si hay un\n",
    "#1 significa que el pixel es blanco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. ¿Qué pinta tienen las etiquetas de training?\n",
    "y_train\n",
    "#Son las etiquetas de los numeros pixelados en el dataset training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4. Imprime la cuarta imagen del dataset de training\n",
    "plt.matshow(x_train[3], cmap = 'gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vas a darle la forma adecuada a los datasets de training y test para poder meterlos a la red neuronal. Pasa las labels, que ahora mismo son números, a su forma categórica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 28, 28, 1))\n",
    "x_train = x_train.astype('float32') / 255\n",
    "\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compila el modelo indicando cuales son los datos de entrenamiento y sus etiquetas. Utilizando el optimizador \"rmsprop\" y como loss function usa la entropía cruzada categórica.\n",
    "Entrena después el modelo durante 5 épocas y un tamaño de batch de 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 17s 17ms/step - loss: 0.1764 - accuracy: 0.9458\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0481 - accuracy: 0.9852\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 16s 17ms/step - loss: 0.0330 - accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0252 - accuracy: 0.9920\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 15s 16ms/step - loss: 0.0204 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a44c6cbf40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=5, \n",
    "          batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a evaluar el modelo con las imágenes de test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0095 - accuracy: 0.9969\n",
      "0.9969000220298767\n"
     ]
    }
   ],
   "source": [
    "#Voy a ver tambien los valores en training\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "print(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0240 - accuracy: 0.9929\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprime la accuracy del test que acabas de realizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.992900013923645\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una imagen con un número escrito a mano y mira cual es la predicción. Prueba con unos cuantos números...¿Lo hace bien? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pcalatayud\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:107: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_width=28\n",
    "img_height=28\n",
    "\n",
    "img = image.load_img('ocho.png', target_size=(img_width, img_height),grayscale=True)\n",
    "x= image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el modelo que acabas de guardar (load) y haz una predicción (predict_classes) con la imágen del número que acabas de escribir.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('CNN_PABLO_CALATAYUD_MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('CNN_PABLO_CALATAYUD_MNIST.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_list=model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero=np.argmax(np.array(numero_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero predicho: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Numero predicho:\",numero)\n",
    "plt.gray() \n",
    "plt.matshow(img) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El modelo acierta el numero entregado como input\n",
    "#Conclusion\n",
    "\n",
    "#Con redes neuronales de deep learning convoluciones es \n",
    "#posible hacertar un 99% en el dataset train de MNIST\n",
    "#y acertar un 99% de las veces en el dataset de test. \n",
    "\n",
    "#Son resultados bastante impresionantes que demuestran \n",
    "#el potencial de las redes convolucionales. En los modelos vistos anteriormente\n",
    "#en el master estabamos en torno al 90%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
