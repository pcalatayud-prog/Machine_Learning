{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 2 - Machine Learning I\n",
    "El objetivo es diseñar una red neuronal que sea capaz de predecir el valor de la precipitación mediante la información de variables de larga escala. El dataset consiste en 450 predictores y un predictando, la precipitación en Madrid.\n",
    "Hay que tener en cuenta que la precipitación es una variable mixta, ya que habrá días con un valor exacto de 0 y otros que se encuentren en el intervalo (0,inf).\n",
    "Así pues, diseñar una red neuronal con KERAS, que sea capaz de predecir la precipitación de acuerdo con los siguientes índices:\n",
    "- La ocurrencia de precipitación se evalúa con el AUC. \n",
    "- La cantidad de precipitación se evalúa con el MSE.\n",
    "\n",
    "Podréis valeros de todas las técnicas aprendidas hasta ahora: early stopping, regularización, backpropagation + momento, ajustar el learning rate, poner varias capas y demás. Esto no quiere decir que la red que contenga toda esta variedad de técnicas será la que obtenga un menor error. Tenéis que jugar y probar distintos diseños de redes con el fin de encontrar la que consideréis que obtendría un menor error en un dataset distinto (es decir, que tenga buena capacidad de generalización).\n",
    "\n",
    "Construiréis vuestro modelo usando xTrain e yTrain, y después evaluaréis el modelo en xTest. La predicción que resulte al evaluar el modelo en xTest es lo que tenéis que guardar en un fichero y lo que se envía para corrección:\n",
    "save(yTest_ocu, yTest_cantidad,  file = “1erApellido_Nombre.rda”)\n",
    "e.g., save(yTest_ocu, yTest_cantidad, file = “Baño_Jorge.rda”)\n",
    "\n",
    "\n",
    "**NOTA: se considera día de lluvia si el valor de precipitación es mayor que 1, sino convertir a 0.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además deberéis de responder a las siguiente cuestiones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**He resuelto el problema en RSTUDIO por problemas con keras en jupyer. \n",
    "Dejo aqui el código usado en R**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- ¿Cómo has preprocesado los datos y por qué (por ejemplo, has estandarizado el predictando o los predictores)? **Descríbe** el proceso en 3-4 líneas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1. Lectura/Carga de fichero de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos la libreria correspondiente\n",
    "library(keras)\n",
    "library(tensorflow)\n",
    "library(reticulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(file=\"Madrid_Alumno.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install_keras()\n",
    "install_tensorflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2. Preprocesado de datos. Normalizacion de los datos en base al dataSet Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest_normalization <- function(train,test) {\n",
    "  #Input:\n",
    "  #train: train Set predictors\n",
    "  #test: test set predictors  \n",
    "  \n",
    "  #Inicializamos la matriz de test\n",
    "  \n",
    "  xtest <- matrix(0,nrow(test),ncol(test))\n",
    "  #sd y mean del xTrain para cada predictor\n",
    "  sd1 <- apply(train,2,sd)\n",
    "  mean1 <- apply(train,2,mean)\n",
    "  \n",
    "  for (i in 1:ncol(test)) {\n",
    "    # escalamos el xTest\n",
    "    # (x - mean(x)) / sd(x)\n",
    "    xtest[,i] <- ((test[,i]-mean1[i])/sd1[i])\n",
    "  }\n",
    "  return(xtest)\n",
    "  \n",
    "  #Output:\n",
    "  #xtest: conjunto de test escalado\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamos xTest con la funcion anterior\n",
    "xTest <- xTest_normalization(xTrain,xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aplicamos la normalizacion al train set\n",
    "xTrain <- apply(xTrain, 2, function(x) (scale(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Es importante el orden en el cual normalizamos los datos. Primero normalizamos test con el train \n",
    "#y despues normalizamos el train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'xTrain' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'xTrain' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#Veamos un poco los datos y sus dimensiones\n",
    "dimensiones_train=dim(xTrain)\n",
    "dimensiones_test=dim(xTest)\n",
    "cat(\"Train. Número de datos:\",dimensiones_train[1])\n",
    "cat(\"\\n\")\n",
    "cat(\"Train. Número de Dimensiones:\",dimensiones_train[2])\n",
    "cat(\"\\n\")\n",
    "cat(\"Test. Número de datos:\",dimensiones_test[1])\n",
    "cat(\"\\n\")\n",
    "cat(\"Test. Número de Dimensiones:\",dimensiones_test[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- ¿Qué topología de red neuronal has encontrado óptima para la **ocurrencia de precipitación**? **Describe** en 3-4 líneas por qué has usado esta topología e incluye el **código de Keras** (mirar ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Describe en 3-4 líneas ----------------------\n",
    "\n",
    "#He probado diferentes tipos de arquitecturas pero al final me he decantado por una arquitectura de tipo VAE\n",
    "#para ambos casos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain_occ <- ifelse(yTrain<=1,0,1) #Convertir lluvia a binario (occurencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class <- keras_model_sequential() \n",
    "\n",
    "#Topologia tipo VAE\n",
    "inputs = layer_input(shape = dimensiones_train[2])\n",
    "#Ponemos el numero de columnas de mnist\n",
    "x = inputs\n",
    "l1 = layer_dense(x,units = 10, activation = \"sigmoid\")\n",
    "l2a = layer_dense(l1,units = 20, activation = \"sigmoid\")\n",
    "l2b = layer_dense(l1,units = 20)\n",
    "l3 = layer_add(list(l2a,l2b))#combinacion lineal\n",
    "l3_activated = layer_activation(l3,activation = \"sigmoid\")\n",
    "outputs = layer_dense(l3_activated,units = 1, activation = \"sigmoid\")\n",
    "\n",
    "# model <- keras_model(inputs = inputs, outputs = outputs)\n",
    "model_class <- keras_model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model_class %>% compile(loss = 'binary_crossentropy',\n",
    "                  optimizer = optimizer_sgd(learning_rate = 0.01), \n",
    "                  metrics = 'accuracy')\n",
    "\n",
    "callbacks = list(callback_early_stopping(patience = 15),\n",
    "                 callback_model_checkpoint(filepath=paste0('model1_occ.h5'),\n",
    "                 monitor='accuracy', save_best_only=TRUE))\n",
    "\n",
    "history <- model_class %>% fit(xTrain, yTrain_occ, epochs = 10000, \n",
    "                         batch_size = 128, \n",
    "                         verbose = 1, callbacks=callbacks)   \n",
    "\n",
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONFUSION MATRIX\n",
    "yTrain_occ_pred <- model_class$predict(xTrain)\n",
    "yTrain_occ_pred <- ifelse(yTrain_occ_pred<=0.5,0,1) #Convertir sigmoide binario (occurencia)\n",
    "\n",
    "a=table(as.factor(yTrain_occ_pred),as.factor(yTrain_occ))\n",
    "cat(\"Train Confusion Matrix:\")\n",
    "cat(\"Accuracy Train Occurency: \",(sum(diag(a))) / length(yTrain_occ_pred))\n",
    "\n",
    "yTest_occ <- model_class$predict(xTest)\n",
    "yTest_occ <- ifelse(yTest_occ<=0.5,0,1) #Convertir sigmoide a binario (occurencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- ¿Qué topología de red neuronal has encontrado óptima para la **cantidad de precipitación**? **Describe** en 3-4 líneas por qué has usado esta topología e incluye el **código de Keras** (mirar ejemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La misma red neuronal que en el caso anterior. Cambiando la funcion loss y la ultima capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred <- keras_model_sequential() \n",
    "#Topologia tipo VAE\n",
    "inputs = layer_input(shape = dimensiones_train[2])\n",
    "x = inputs\n",
    "l1 = layer_dense(x,units = 10, activation = \"sigmoid\")\n",
    "l2a = layer_dense(l1,units = 20, activation = \"sigmoid\")\n",
    "l2b = layer_dense(l1,units = 20)\n",
    "l3 = layer_add(list(l2a,l2b))#combinacion lineal\n",
    "l3_activated = layer_activation(l3,activation = \"sigmoid\")\n",
    "outputs = layer_dense(l3_activated,units = 1, activation = \"linear\")\n",
    "\n",
    "model_pred <- keras_model(inputs = inputs, outputs = outputs)\n",
    "\n",
    "model_pred %>% compile(loss = 'mse',\n",
    "                       optimizer = optimizer_sgd(learning_rate=0.01))\n",
    "\n",
    "callbacks = list(callback_early_stopping(patience = 15),\n",
    "                 callback_model_checkpoint(filepath=paste0('model1_reg.h5'),\n",
    "                                           monitor='loss', save_best_only=TRUE))\n",
    "\n",
    "history_pred <- model_pred %>% fit(xTrain, yTrain, epochs = 10000, \n",
    "                         batch_size = 128, \n",
    "                         verbose = 1, callbacks=callbacks)   \n",
    "\n",
    "plot(history_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculo de la precipitacion predicha para test y train\n",
    "yTest_reg_pred   <- model_pred$predict(xTest)\n",
    "yTrain_reg_pred <- model_pred$predict(xTrain)\n",
    "\n",
    "\n",
    "yTrain_reg <- as.numeric(yTrain_occ) * as.numeric(yTrain_reg_pred)\n",
    "yTest_reg  <- as.numeric(yTest_occ) * as.numeric(yTest_reg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ocurrencia binario\n",
    "#---------------------------------\n",
    "cat(\"Accuracy Train Occurency: \",(sum(diag(a))) / length(yTrain_occ_pred))\n",
    "cat(\"tabla\")\n",
    "print(a)\n",
    "#Lluvia regresion\n",
    "#---------------------------------\n",
    "rmse <- function(x, y) {\n",
    "  stopifnot(length(x) == length(y))\n",
    "  sqrt(mean((x - y)^2))\n",
    "}\n",
    "\n",
    "cat(\"Train precipitation prediction RMSE\",rmse(yTrain_reg,yTrain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(yTest_ocu,yTest_reg,file=\"calatayud_pablo.rda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resultados\n",
    "\n",
    "#En ocurrencia tengo un acierto del 100%\n",
    "\n",
    "#En prediccion de cantidad de lluvia tengo un RNSE de 0.6713\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nota: No he podido ejecutar este notebook por el problema con la libreria. Espero que no haya problema al \n",
    "#ser ejecutado. Si hay algún problema puedo enviar mi codigo en R."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
