{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#[Profesores:-Steven-Van-Vaerenbergh,-Rodrigo-G.-Manzanas,-Joaquín-Bedia-y-Sixto-Herrera]\" data-toc-modified-id=\"[Profesores:-Steven-Van-Vaerenbergh,-Rodrigo-G.-Manzanas,-Joaquín-Bedia-y-Sixto-Herrera]-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>[Profesores: Steven Van Vaerenbergh, Rodrigo G. Manzanas, Joaquín Bedia y Sixto Herrera]</a></span></li></ul></li><li><span><a href=\"#Introducción:-Reducción-de-la-Dimensión\" data-toc-modified-id=\"Introducción:-Reducción-de-la-Dimensión-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción: Reducción de la Dimensión</a></span><ul class=\"toc-item\"><li><span><a href=\"#PCAs-(función-prcomp)\" data-toc-modified-id=\"PCAs-(función-prcomp)-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>PCAs (función <a href=\"https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp\" target=\"_blank\">prcomp</a>)</a></span></li></ul></li><li><span><a href=\"#Tarea-2.-Problemas-de-Clasificación---Reducción-de-la-Dimensión\" data-toc-modified-id=\"Tarea-2.-Problemas-de-Clasificación---Reducción-de-la-Dimensión-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tarea 2. Problemas de Clasificación - Reducción de la Dimensión</a></span><ul class=\"toc-item\"><li><span><a href=\"#Punto-1-(3-puntos):\" data-toc-modified-id=\"Punto-1-(3-puntos):-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Punto 1 (3 puntos):</a></span></li><li><span><a href=\"#Punto-2-(3-puntos):\" data-toc-modified-id=\"Punto-2-(3-puntos):-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Punto 2 (3 puntos):</a></span></li><li><span><a href=\"#Punto-3-(2-puntos):\" data-toc-modified-id=\"Punto-3-(2-puntos):-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Punto 3 (2 puntos):</a></span></li><li><span><a href=\"#Punto-4-(2-puntos):\" data-toc-modified-id=\"Punto-4-(2-puntos):-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Punto 4 (2 puntos):</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Minería de Datos (Master en Data Science, UIMP-UC) \n",
    "### [Profesores: Steven Van Vaerenbergh, Rodrigo G. Manzanas, Joaquín Bedia y Sixto Herrera]\n",
    "\n",
    "\n",
    "## Introducción: Reducción de la Dimensión\n",
    "\n",
    "En la presente tarea trabajaremos con datos de variables climáticas los cuales por lo general presentan una alta auto-correlación espacial, rangos muy diferenciados y correlación entre variables, entre otros \"problemas\" citados a lo largo del curso.\n",
    "\n",
    "Como habéis visto en las sesiones de Reducción de la Dimensión con Técnicas No Lineales, estos métodos suelen ser un pre-proceso habitualmente aplicado para resolver dichos problemas. Es por ello que en parte de la presente tarea exploraremos dichas técnicas, sea en su versión lineal (PCAs) o no lineal (KPCAs). Para ello, en esta subsección introduciremos brevemente las funciones en R que aplican ambos métodos.\n",
    "\n",
    "### PCAs (función [prcomp](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp))\n",
    "\n",
    "El análisis de componentes principales (PCAs) está implementado en R a través de la función `prcomp` (`?prcomp`). Veamos como hacer uso de dicha función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  .default = col_double()\n",
      ")\n",
      "\n",
      "See spec(...) for full column specifications.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 5\n",
      " $ sdev    : num [1:784] 592 515 460 439 406 ...\n",
      " $ rotation: num [1:784, 1:784] -2.11e-18 8.88e-16 -3.33e-16 0.00 1.11e-16 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : chr [1:784] \"pixel0\" \"pixel1\" \"pixel2\" \"pixel3\" ...\n",
      "  .. ..$ : chr [1:784] \"PC1\" \"PC2\" \"PC3\" \"PC4\" ...\n",
      " $ center  : Named num [1:784] 0 0 0 0 0 0 0 0 0 0 ...\n",
      "  ..- attr(*, \"names\")= chr [1:784] \"pixel0\" \"pixel1\" \"pixel2\" \"pixel3\" ...\n",
      " $ scale   : logi FALSE\n",
      " $ x       : num [1:1000, 1:784] -629 1736 -841 -178 1960 ...\n",
      "  ..- attr(*, \"dimnames\")=List of 2\n",
      "  .. ..$ : NULL\n",
      "  .. ..$ : chr [1:784] \"PC1\" \"PC2\" \"PC3\" \"PC4\" ...\n",
      " - attr(*, \"class\")= chr \"prcomp\"\n"
     ]
    }
   ],
   "source": [
    "library(\"readr\")\n",
    "mnist_data <- read_csv(\"./train.csv\")\n",
    "nrows <- 1000 # set number of rows to include. Max = 42000\n",
    "PCA1 <- prcomp(mnist_data[1:nrows,(2:ncol(mnist_data))], center = TRUE, scale. = FALSE) # PCA with R\n",
    "str(PCA1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Como vemos la función devuelve un `data.frame` con los siguientes elementos:\n",
    "\n",
    " * `sdev`: Se corresponde con la desviación estándar asociada a cada componente principal.\n",
    " * `rotation`: Es la matriz de cambio de base, desde el espacio original al espacio de las CPs.\n",
    " * `center`: Es el vector de medias de las variables originales.\n",
    " * `scale`: Es el vector de desviaciones estándar de las variables originales. Junto con `center` son los elementos aplicados para normalizar las variables orginales.\n",
    " * `x`: Es la matriz con las coordenadas de los diferentes elementos de la muestra en el espacio de las CPs. En un modelo que utilice CPs serán, por tanto, las nuevas variables de entrada.\n",
    "\n",
    "Una vez hemos obtenido las PCs y entrenado un modelo, para aplicar éste a nuevos datos (test) deberemos reproyectar los nuevos datos al espacio de las PCs con la función `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "PCAtest <- predict(PCA1, newdata = mnist_data[1001:2000,(2:ncol(mnist_data))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "En el recurso `07 Reducción de la dimensión` incluido en el Moodle de la asignatura tienes toda la información detallada a este respecto.\n",
    "\n",
    "\n",
    "## Tarea 2. Problemas de Clasificación - Reducción de la Dimensión\n",
    "\n",
    "En la presente tarea consideraremos el dataset `meteo.csv`, que podéis descargaros en el GitHub dedicado a este Máster ([meteo.csv](https://github.com/SantanderMetGroup/Master-Data-Science/blob/master/Data_mining/datasets/meteo.csv.)) y que ha sido utilizado en diferentes sesiones prácticas. Dicho dataset contiene en la primera columna el valor de precipitación observado en Lisboa en el periodo 1979-2008 mientras que en las restantes contiene los valores observados de diferentes variables atmosféricas en 40 puntos que cubren aproximadamente la Península Ibérica. Dichas variables serán los `predictores` del modelo mientras que la precipitación será nuestra variable objetivo. En particular los predictores son:\n",
    "\n",
    "* Altura geopotencial en 500 hPa (columnas 2:41),\n",
    "* Temperatura del aire en 850 hPa (columnas 42:81), 700 hPa (columnas 82:121) y 500 hPa (columnas 122:161), \n",
    "* Temperatura del aire en superficie (columnas 162:201),\n",
    "* Humedad específica del aire en 850 hPa (columnas 202:241) y 500 hPa (columnas 242:281) y \n",
    "* Presión al nivel del mar (columnas 282:321)\n",
    "\n",
    "Para establecer el problema de clasificación consideraremos dos umbrales de discretización, 1 mm y 20 mm, que definen la ocurrencia de precipitación (Wet days) y de precipitaciones intensas (Very heavy precipitation days), respectivamente. Puedes consultar más detalles de la definición en la web de [ECA&D](https://www.ecad.eu//indicesextremes/indicesdictionary.php).\n",
    "\n",
    "Para el desarrollo de la tarea se permitirá el uso de todo el material incluido en el Moodle de las asignatura así como el desarrollado por el alumno durante la realización de las prácticas.\n",
    "\n",
    "La entrega consisitirá de un notebook de Jupyter ó un R-MarkDown, junto con el archivo html que éste genera. Ambos ficheros se entregarán a través del Moodle de la asignatura en la tarea correspondiente.\n",
    "\n",
    "### Punto 1 (3 puntos):\n",
    "\n",
    "Considerad la serie de precipitación discretizada a partir del valor 1 mm, que es el estándar definido para establecer los días en que ha llovido. El objetivo de este apartado es predecir la ocurrencia de precipitación en Lisboa a partir de los predictores originales. Para ello consideraremos el método `KNN`. Dividir la muestra en dos subconjuntos, el primero (20 primeros años) lo utilizaremos para calibrar el modelo y obtener su configuración óptima, mientras que el segundo (10 últimos años) lo utilizaremos como test independiente de cara a comparar diferentes métodos.\n",
    "\n",
    "* Obtened el valor óptimo de `K` en cada rastreando valores entre 1 y 15, ¿cambia el valor óptimo si normalizamos las variables originales (`? scale`)? En base a los resultados obtenidos, ¿considerarías las variables originales o normalizadas? En base al coste computacional del entrenamiento ¿consideras cierto que el método `KNN` se ve muy afectado por la dimensionalidad del espacio de trabajo?\n",
    "* Para la configuración óptima calibrada con el conjunto de entrenamiento realizad la predicción sobre el conjunto de test y estimad los errores cometidos sobre este conjunto.\n",
    "\n",
    "`Nota 1:` en principio es posible trabajar con el dataset completo sin seleccionar un subconjunto pero si surge algún problema de memoria podéis considerar únicamente los primeros 10 años (~3650 filas).\n",
    "\n",
    "`Nota 2:` usad las herramientas gráficas vistas durante la práctica para ilustrar los resultados y las conclusiones obtenidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Punto 2 (3 puntos):\n",
    "\n",
    "Dados los posibles problemas asociados a la dimensionalidad del espacio de trabajo, en adelante consideraremos como predictores las Componentes Principales en lugar de las variables originales. Para ello, obtén las CPs a partir de los predictores originales del dataset `meteo.csv`. Recuerda la necesidad (o no) de estandarizar las variables para la obtención de las CPs (`Nota:` consultar la ayuda de la función scale -> `? scale`).\n",
    "\n",
    "A continuación, volveremos a considerar la serie de precipitación discretizada a partir del valor 1 mm y predecir la ocurrencia de precipitación en Lisboa a partir de los predictores antes definidos a partir de las CPs. Para ello consideraremos, por un lado, las componentes principales obtenidas estandarizando los datos originales y, por otro lado, el método `KNN`. Dividir la muestra en dos subconjuntos, el primero (20 primeros años) lo utilizaremos para calibrar el modelo y obtener su configuración óptima, mientras que el segundo (10 últimos años) lo utilizaremos como test independiente de cara a comparar diferentes métodos.\n",
    "\n",
    "* Considerad diferentes umbrales de varianza explicada y el número de PCs asociado (p.e. 40%, 60%, 80% y 90%) y obtened el valor óptimo de `K` en cada caso rastreando valores entre 1 y 15, ¿cómo cambia el valor óptimo? En base a los resultados obtenidos, ¿cuantas PCs considerarías para entrenar el modelo? (`Nota:` ver práctica de `KNN`)\n",
    "* Para la configuración óptima calibrada con el conjunto de entrenamiento realizad la predicción sobre el conjunto de test y estimad los errores cometidos sobre este conjunto.\n",
    "\n",
    "### Punto 3 (2 puntos):\n",
    "\n",
    "Repetid el experimento anterior considerando la precipitación discretizada a partir del valor 20 mm, que es el estándar definido para establecer los días en que ha llovido de forma intensa.\n",
    "\n",
    "* ¿Cómo cambian los valores óptimos de `K` y de número de PCs? \n",
    "* ¿Cómo cambian los errores sobre el conjunto de test en este caso?\n",
    "* En caso de existir diferentes significativas en ambos casos, ¿a qué crees que puede ser debido? ¿La frecuencia en la muestra del evento a predecir puede influir en la calidad de la predicción?\n",
    "\n",
    "### Punto 4 (2 puntos):\n",
    "\n",
    "Considerando el número de PCs óptimo obtenido en el apartado anterior, predecid el conjunto de test utilizando en este caso la regresión logística como método de clasificación (`Nota:` ver `Práctica Clasificacion Lineal` en el Moodle de la asignatura de Estadística o en la de Minería de Datos). \n",
    "\n",
    "* Comparad los resultados obtenidos utilizando ambos métodos para la predicción de la ocurrencia de precipitación y de precipitación intensa (`Nota:` considerar, por ejemplo, la curva ROC para la comparación), ¿alguno de los métodos se comporta mejor que el otro de forma sistemática?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
